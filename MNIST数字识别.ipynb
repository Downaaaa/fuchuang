{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66bd23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1、加载库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d5c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2、定义超参数\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "EPOCHS = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e11114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3、构建pipeline,对图像做处理\n",
    "pipeline = transforms.Compose([\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "175bff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17513\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "#4、下载、加载数据\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = datasets.MNIST(\"data\",train=True, download=True, transform=pipeline )\n",
    "test_set = datasets.MNIST(\"data\",train=False, download=True, transform=pipeline )\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6497a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5、构建网络模型\n",
    "\n",
    "\"\"\"\n",
    "模型设计：开始->卷积->激活->池化->卷积->激活->池化->全连接->激活->全连接->结束\n",
    "\n",
    "\"\"\"\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,5)\n",
    "        self.conv2 = nn.Conv2d(10,20,3)\n",
    "        self.fc1 = nn.Linear(20*5*5,1000)\n",
    "        self.fc2 = nn.Linear(1000,200)\n",
    "        self.fc3 = nn.Linear(200,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        input_size = x.size(0) #拿到开始定义的超参数batch_size=32\n",
    "        x = self.conv1(x) #输入为batch_size*1*28*28   输出batch_size*10*24*24 (28-5+1=24)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2,2) #输出为batch_size*10*12*12\n",
    "        \n",
    "        x = self.conv2(x) #输出为batch_size*20*10*10（12-3+1=10）\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2,2) #输出为batch_size*20*5*5\n",
    "        \n",
    "        x = x.view(input_size, -1)#拉平\n",
    "        \n",
    "        x = self.fc1(x)#输出为batch_size*500\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)#输出为batch_size*10  ，10个类别\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.log_softmax(x,dim=1) #计算分类后每个数字的概率值\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d160216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6、定义优化器\n",
    "model = Net().to(DEVICE)#创建一个模型并部署到设备上\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f27e3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7、定义训练方法\n",
    "def train_model(model,device,train_loader,optimizer,epoch):\n",
    "    #模型训练\n",
    "    model.train()\n",
    "    for batch_index, (data , target) in enumerate(train_loader):\n",
    "        #部署到设备上\n",
    "        data,target = data.to(device),target.to(device)\n",
    "        #梯度初始化\n",
    "        optimizer.zero_grad()\n",
    "        #训练后的结果\n",
    "        output = model(data)\n",
    "        #计算损失\n",
    "        loss=F.cross_entropy(output,target)\n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        #参数优化\n",
    "        optimizer.step()\n",
    "        if batch_index % 3000 == 0:\n",
    "            print(\"Train Epoch : {} \\t Loss : {:.6f}\".format(epoch,loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f03571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8、定义测试方法\n",
    "def test_model(model,device,test_loader):\n",
    "    #模型验证\n",
    "    model.eval()\n",
    "    #正确率\n",
    "    correct = 0.0\n",
    "    #测试损失\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            #部署到设备上\n",
    "            data,target = data.to(device),target.to(device)\n",
    "            #测试数据\n",
    "            output = model(data)\n",
    "            #计算损失\n",
    "            test_loss += F.cross_entropy(output,target).item()\n",
    "            #找到概率值最大的下标\n",
    "            pred=output.argmax(dim=1)\n",
    "            #累计正确的值\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(\"Test --- Average  loss : {:.4f},Accuracy : {:.3f}\\n\".format(test_loss,100.0*correct/len(test_loader.dataset)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a8caa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17513\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 1 \t Loss : 2.308303\n",
      "Test --- Average  loss : 0.0004,Accuracy : 98.310\n",
      "\n",
      "Train Epoch : 2 \t Loss : 0.037628\n",
      "Test --- Average  loss : 0.0004,Accuracy : 98.520\n",
      "\n",
      "Train Epoch : 3 \t Loss : 0.048102\n",
      "Test --- Average  loss : 0.0003,Accuracy : 98.830\n",
      "\n",
      "Train Epoch : 4 \t Loss : 0.024838\n",
      "Test --- Average  loss : 0.0002,Accuracy : 98.940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#9、调用7和8\n",
    "for epoch in range(1,EPOCHS + 1):\n",
    "    train_model(model,DEVICE,train_loader,optimizer,epoch)\n",
    "    test_model(model,DEVICE,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b78774",
   "metadata": {},
   "source": [
    "face parsing\n",
    "\n",
    "thermal\n",
    "\n",
    "谷歌学术\n",
    "\n",
    "LETPUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d45880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
